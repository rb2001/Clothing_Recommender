# -*- coding: utf-8 -*-
"""Copy of Clothing_Recommender Project .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h3NMCrr6oFRx6_7mzHoA7siOnIrzJuyx

Load Data, Setup Test and Train Data

Optimize Dataset
"""
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import pydeck as pdk

DATE_TIME = "age"
DATA_URL = (
    "CleanedData.csv"
)

st.title("Clothing Recommender System")
st.subheader('Built by The Togs')
st.markdown(
"""
Implementing a clothing purchase recommendation system based on E-commerce clothing datasets intended to aid customers in the purchase of preferable clothes
Technologies used: Python libraries (Pandas, Numpy, Matplotlib, SciPy, Scikit-learn) to model data with convolutional neural networks and KNN based collaborative filtering. 
[See source code](https://github.com/katejkpark/ML-Clothing)
Get your clothing recommendations now!
""")

@st.cache(persist=True)
def load_data(nrows):
    data = pd.read_csv(DATA_URL, nrows=nrows)
    lowercase = lambda x: str(x).lower()
    data.rename(lowercase, axis="columns", inplace=True)
    data[DATE_TIME] = pd.to_datetime(data[DATE_TIME])
    return data


data = load_data(100000)

df=pd.read_csv('CleanedData.csv', sep=',') 

import pandas as pd 
import numpy as np 
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import nan_euclidean_distances
from sklearn.metrics import mean_squared_error
import random
random.seed(10)


#read clean file (downloaded from Task 1)
df=pd.read_csv('CleanedData.csv', sep=',') 


#Pivot table (clothingID, age, rating) - Nan is replaced with 0 
data = df.pivot_table(index='Age', columns='ClothingID', values='Rating')




#split the data into train and test *test is the ANSWER KEY 
train, test = train_test_split(data, test_size=0.25, random_state = 59) #shuffled but split the same everytime 
train = train.sort_values('Age', ascending=True)
test = test.sort_values('Age', ascending=True)

#building test input data
inputArray = pd.DataFrame().reindex_like(test).dropna()

#randomly get single data set from test data row  
for Age in test.index:
  x = test.loc[[Age]] #get first row from test data
  x = x.dropna(axis=1).sample(axis=1) #take a valid sample from test data 
  CID_test = x.columns.values[0] #set CID_test to Clothing ID of selected sample 
  rating_test = x.values[0][0] #set rating_test to rating of selected sample

  #create array with singular test data 
  sampleArray = pd.DataFrame().reindex_like(train)
  sampleArray.dropna(thresh=1,inplace=True)
  sampleArray.loc[Age,CID_test] = rating_test #enter user data 
  inputArray = inputArray.append(sampleArray)

##Issue with the Matrix - there are values greater than 5 and the original data is not matching##

#Function to find Optimum K (i.e. minimum RMSE)"""

def find_rms(k):
  rmsVal = []

  meanArray = pd.DataFrame().reindex_like(test).dropna()
################
  for Age, row in inputArray.iterrows(): #for every user in the inputarray
    
    
    distance = np.zeros((0,2)) #create empty array 
    for i, row in train.iterrows():  #for each row of train
      result_array = [i, float(nan_euclidean_distances([inputArray.loc[Age]], [train.loc[i]]))] #place distance into array 
      distance = np.append(distance,[result_array],axis= 0) 
    
    #convert array to a dataframe
    dfDistance = pd.DataFrame({'Age': distance[:, 0], 'E-Distance': distance[:, 1]})

    #sort by distance, reset the index 
    dfDistance = dfDistance.sort_values('E-Distance', ascending=True).nsmallest(k, 'E-Distance') #sort by distance, keep only the k smallest  distances  

    k_array = pd.DataFrame().reindex_like(test).dropna() #20,1095  

    for x in dfDistance['Age']: 
      k_array = k_array.append([train.loc[x]]) #make array of the k closest ages from training data 
  
    meanArray = meanArray.append([k_array.mean()]).rename(index = {0: Age}) #find the mean of rows in k_array and add each to the tempArray
  
#################
  
  meanArray.index.name = 'Age'
  
  #compare test and and predicted values 
  rms = np.sqrt(mean_squared_error(test.fillna(random.uniform(1,5)), meanArray.fillna(random.uniform(1,5)))) ###REMOVE THIS BEFORE DEMO **RANDOMIZED TO TEST PLOT ******************************************!!!!!!
 
  rmsVal.append(rms)
  return rmsVal

def optimal_k():
  k_list = [3,4,5] 

  rmsList = list(map(find_rms, k_list))

  k = k_list[rmsList.index(min(rmsList))]

 
  
  return k

"""Get User Data"""

###Create a greeting 

###Create a greeting 
st.markdown(
"""
Welcome, let us recommend a product for you:
""")

#Take user input 

#Take user input 
Name = st.text_input('Please enter your name: ')
Age = st.number_input('Please enter your age: ')
rating_user = st.number_input("Enter Rating for Clothing ID: ")
CID_user = st.number_input('Enter Clothing ID: ') #90
if CID_user not in train.columns:
  st.write('Invalid: No data for ID')
else:
  st.number_input("Enter Valid for Clothing ID: ") #4

##Determine Euclidean Distances, Pick k best distances"""

##use this later (if user has more than one rating to enter)
#entries = int(input("How many ratings will you enter? "))
#for x in range(entries):

#create array with user data 
userArray = pd.DataFrame().reindex_like(train)
userArray.dropna(thresh=1,inplace=True)
userArray.loc[Age,CID_user] = rating_user #enter user data 

from sklearn.metrics.pairwise import nan_euclidean_distances

#find euclidean distance between all rows of data and first row of test  *ignores nan
distance = np.zeros((0,2)) #create empty array 


for index, row in train.iterrows():  #iterate through each row of train 
  result = float(nan_euclidean_distances([userArray.loc[Age]], [train.loc[index]])) #compute the euclidean distance between two rows, *confirmed it works thru excel
  result_array = [index, result] #place age and distance into an array 
  distance = np.append(distance,[result_array],axis= 0) 

#convert array to a dataframe
dfDistance = pd.DataFrame({'Age': distance[:, 0], 'E-Distance': distance[:, 1]})


k= optimal_k()
#sort by distance, reset the index 
dfDistance = dfDistance.sort_values('E-Distance', ascending=True).head(20)
dfDistance = dfDistance.reset_index(drop=True) 
dfDistance.drop(dfDistance[dfDistance.index > k-1].index, inplace=True)
dfDistance.head()

"""Predict Ratings for User, Recommend the best 5 Items"""

#NOTE: for calculating the predicted rating, could use an IDW Interpolation function shown here https://stackoverflow.com/questions/3104781/inverse-distance-weighted-idw-interpolation-with-python
#just using mean of each to test a solution, will come back and try more complex/accurate functions later 

#assume k of 5####
k_array = pd.DataFrame().reindex_like(train)
meanArray = pd.DataFrame()

for x in dfDistance['Age']:
  k_array = k_array.append([train.loc[x]]) #make array of the k closest ages

meanArray = meanArray.append(k_array.mean(),ignore_index = True).transpose()
meanArray.dropna(axis=0,inplace=True)
meanArray.columns = ["Mean"]
meanArray = meanArray[meanArray.Mean == 5]

recommend = list(meanArray.index.values)

new = df[['ClothingID', 'Department Name']].copy()
new = new.drop_duplicates(subset=['ClothingID']).set_index('ClothingID').loc[recommend]
department = st.text_input("What department would you like to look at next? (Tops, Intimate, Bottoms, Dresses, Jackets): ")
st.write("Some clothes you might also enjoy include: ")
new = st.write(new[new['Department Name'].str.match(department)]) #just outputs the selected department data (does not change the dataframe)
